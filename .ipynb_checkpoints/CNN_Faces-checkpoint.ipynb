{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "soviet-digit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 6, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=2, bias=True)\n",
      ")\n",
      "Training data count: 403\n",
      "Test data count: 171\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.688055  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.004067 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.676022  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.004001 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.741516  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003981 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.769618  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.781172  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003972 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.785651  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.787089  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.787237  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.786866  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.786359  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003972 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.785797  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003972 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.785236  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003972 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.784660  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003973 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.784160  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003973 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.783746  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.783367  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.782991  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.782572  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.782048  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.781562  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.781079  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003974 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.780722  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003973 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.780453  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003973 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.780246  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003972 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.780342  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003972 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.780052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.780338  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.780125  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003970 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.780136  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003969 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.780082  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003969 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.780037  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003968 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.780336  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003967 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.780370  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003965 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.780342  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003964 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.780401  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003962 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.780394  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003960 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.780597  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003955 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.778042  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003952 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.777840  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003951 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.781554  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003948 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.783011  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003947 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.789061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003941 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.789538  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003933 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.784988  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003930 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.797956  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003884 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.755349  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003926 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.851410  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003876 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.759391  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003890 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.809392  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003865 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.804224  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.003810 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.753874  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003941 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.028039  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.003650 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.673443  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.003837 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.029024  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.003770 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.869405  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.003851 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.042925  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.003801 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.903014  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.005368 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.101094  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.003788 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.878027  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.003382 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.640785  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.003509 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.645310  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.003547 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.573133  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.003529 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.835174  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.009120 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 3.713411  [    0/  403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 0.003959 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.235467  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.004217 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.392252  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.004054 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.254201  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.004506 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.612188  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.003493 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.776072  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.003605 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.984636  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.003340 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.639948  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.004175 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.453868  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.004350 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.578738  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.003937 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 1.374222  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.003079 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.643267  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.004065 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.400443  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.003962 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.962068  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008874 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 3.275580  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.006086 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.275970  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.006461 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.335802  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.004484 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.765029  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.004617 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.530889  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.004524 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 1.876718  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.005208 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.739391  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.008058 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 3.014265  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.004765 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 1.855296  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.004542 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.635494  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.005315 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.615128  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.006158 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.040158  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.006014 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.153692  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.007194 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.953868  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.002874 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.294528  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.005240 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.494590  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.005177 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.942342  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.005626 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.520930  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.006768 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.205100  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.003349 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.363226  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.005935 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.691200  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.005618 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.427984  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.006886 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.445698  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.010003 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 1.452534  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.004707 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.306153  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.003011 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.285560  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.003476 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.220080  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.003446 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.257012  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.002616 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.607215  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.003660 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.495461  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.002254 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.155196  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.277061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.008164 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.654072  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.003654 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.329938  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.003613 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.185528  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.004182 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.128446  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.004082 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.117637  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.004288 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.095763  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.005094 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.121936  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.004940 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.083212  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.004687 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.105297  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.004999 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.053395  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.005606 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.068935  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.006176 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.059009  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.005560 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.080522  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.008226 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.067214  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.009459 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.192904  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.016654 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 1.968611  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.009731 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.216186  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.008554 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.112367  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.008590 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.108154  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.003502 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.533950  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.004876 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.047242  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.007768 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.049737  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.008283 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.067488  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.008236 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.021979  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.007529 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.021243  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.007550 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.020858  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.008741 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.018596  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.009603 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.023102  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.009631 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.019647  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.009051 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.019348  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.011038 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.020254  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.013657 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.029052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.017663 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.434659  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.005850 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.106407  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.008542 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.026004  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.008647 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.031107  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.004967 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.118255  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.006616 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.037463  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.009293 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.055965  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.006422 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.026263  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.006908 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.023744  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.007733 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.025124  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.007710 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.024971  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.007539 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.025389  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.008291 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.025404  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.008721 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.026988  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.009129 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.028128  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.008679 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.028818  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.008676 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.030758  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.008994 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.031662  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.009228 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.032771  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.009362 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.035010  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.009497 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.013841  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.009667 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.038072  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.009853 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.015522  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.009774 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.017676  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.009875 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.011061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010072 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.005950  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.009992 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.010176  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.009996 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.006593  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010190 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.005052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010417 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.003295  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010548 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.002592  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.010467 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.011375  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010659 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.003034  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010858 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.002105  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010963 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.001695  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010785 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.003662  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.010884 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.001928  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.011070 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.011168 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.001061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.011175 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.005355  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.011379 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.002981  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.011773 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.001571  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012715 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.001486  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.012923 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.000699  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.012996 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.003542  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013016 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013156 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.000878  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013298 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000672  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013424 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.000544  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013263 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.001462  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013248 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.001047  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013426 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.000667  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013613 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.000496  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013554 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.001187  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.013642 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.000418  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.014309 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.000560  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.014849 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.002679  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.015030 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.285686  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.045612 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 4.591325  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.003555 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.274771  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.003490 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.241044  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.004035 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.073872  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.005765 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.062348  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.005986 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.045526  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.006539 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.027942  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.007003 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.020600  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.007746 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.012451  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.006320 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.056609  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.007341 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.032965  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.009173 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.028855  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.008112 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.052976  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.009047 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.011863  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.009412 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.011295  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.009919 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.015875  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.010195 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.009293  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.010331 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.006595  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.010273 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.007106  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.010466 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.005630  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.010691 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.003788  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.010830 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.003083  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.010933 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.002964  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011077 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.002778  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011291 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.002104  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011440 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.001741  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011678 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011522 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.002143  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011592 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.002401  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011791 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.001806  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.011950 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.001480  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012096 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.001245  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012228 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.001077  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.012218 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.001298  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012323 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012449 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.001062  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012559 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.000910  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012664 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.000812  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.012763 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.000732  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.012856 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.000665  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.012832 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000805  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.012906 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000791  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.013017 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.000691  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.013115 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.000625  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.013215 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.000561  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013304 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.000516  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013389 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000475  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013472 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.000441  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013294 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000753  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.013311 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000836  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013433 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000714  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013546 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000635  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.013652 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.000567  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.013749 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.000516  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013833 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.000479  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013909 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.000450  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.013979 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.000425  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014046 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000401  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014114 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000380  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.014068 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.000477  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014098 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.000501  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014182 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.000451  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014255 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.000415  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014320 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000385  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.014381 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.000362  [    0/  403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.014439 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000342  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.014497 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000323  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014549 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000308  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014597 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000295  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014648 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.000282  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014698 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.000269  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014750 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000256  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.014698 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.000318  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.014718 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.000340  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.014784 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.000312  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014847 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000290  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014907 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000271  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.014963 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.000256  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015016 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.000243  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015068 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000231  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015117 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.000220  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.014983 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000542  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.015064 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.000506  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.015144 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000434  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015212 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000381  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015272 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.000341  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015326 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.000312  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015380 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.000288  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015431 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000268  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015479 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.000252  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015524 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000238  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015567 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.000225  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015610 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000214  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015650 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.000204  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015690 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000196  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015727 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000188  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015765 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.000181  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015803 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000174  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015747 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.000213  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015737 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.000234  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015788 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.000220  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015836 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.000207  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015880 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.000197  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015922 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.000188  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.015962 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.000180  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016003 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.000172  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016044 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.000165  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016083 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.000159  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016122 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.000153  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016159 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.000148  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016192 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.000144  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016225 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.000140  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016257 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.000136  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016206 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.000164  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016198 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.000178  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016245 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.000167  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016288 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.000158  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016328 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.000151  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016367 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.000144  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016404 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.000139  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016439 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.000133  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016475 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.000128  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016516 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.000123  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016558 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.000117  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016603 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.000112  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016642 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.000108  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016683 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.000103  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016725 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.000099  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.016761 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.000096  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016507 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.000156  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016551 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.000144  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016624 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000129  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016713 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.000118  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016814 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.000110  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016898 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.000107  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016873 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.000134  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016902 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.000144  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.016981 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.000136  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.017055 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.000129  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.017429 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.000127  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.017728 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.000124  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.017791 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.000117  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.017853 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.000111  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.017914 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.000105  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.017973 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.000100  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018024 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.000096  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018080 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.000092  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018131 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.000088  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018176 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.000085  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018224 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.000081  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018270 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.000078  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.018309 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.000076  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018405 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.000075  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018493 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.000074  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018500 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.000089  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018553 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.000098  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018648 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.000093  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018734 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.000090  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018814 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.000086  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018891 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.000083  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.018964 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.000080  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019032 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.000078  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019100 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.000076  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019164 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.000074  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019229 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.000072  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019291 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.000070  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019348 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.000069  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019407 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019464 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.000065  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019515 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.019569 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019621 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019670 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019717 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019763 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019727 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.000074  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019735 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.000085  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019792 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.000080  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019844 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019894 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.000073  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019943 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.000071  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.019990 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.000068  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020037 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.000066  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020081 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020126 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020167 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020208 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020248 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020287 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.000056  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020325 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020361 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020400 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.000052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020439 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.000051  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020478 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.000051  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020516 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020555 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.020452 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.000070  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020453 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.000086  [    0/  403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020536 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.000082  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020610 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.000079  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020678 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020740 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.000075  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020801 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.000074  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020859 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.000072  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020918 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.000071  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.020974 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.000070  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021027 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.000069  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021078 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.000068  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021127 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021176 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.000066  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021224 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.000066  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021269 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.000065  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021313 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021355 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021396 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021437 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021477 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021517 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021557 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021596 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021634 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021675 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021717 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021758 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021795 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021832 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.000056  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021869 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.000056  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021907 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021944 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.021980 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022018 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022054 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.000053  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022023 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.000068  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022012 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022046 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.000074  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022084 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.000072  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022122 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.000069  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022158 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022193 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.000066  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022228 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022260 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022292 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022323 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022354 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022383 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022411 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022438 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.000056  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022466 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022493 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022520 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.000053  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022548 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.000052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022574 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.000052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022601 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.000051  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022490 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.000076  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022432 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.000093  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022466 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.000086  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022499 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.000081  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022530 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022561 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.000074  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022591 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.000071  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022620 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.000068  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022649 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.000066  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022677 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022704 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022727 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/  403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022751 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022773 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022796 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022818 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.000056  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022840 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022862 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022883 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.000053  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022904 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.000052  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.022925 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.000051  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022944 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.000051  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022964 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.022984 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023003 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.000048  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023021 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.000048  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023039 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.000047  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023057 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.000046  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023075 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.000046  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023094 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023112 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023130 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.000044  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023149 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.000044  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023168 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.000043  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023187 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.000043  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023205 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.000042  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023224 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.000042  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023242 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.000041  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023261 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.000041  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023279 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.000041  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023297 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023314 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023332 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023349 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.000039  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023366 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.000039  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023383 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.023324 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.023290 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.000056  [    0/  403]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.023310 \n",
      "\n",
      "Done!\n",
      "Saved PyTorch Model State to \"D:\\faceintrec\\CNN\\model\\model.pth\"\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import torch, os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "#LoadData\n",
    "import yaml\n",
    "import cv2\n",
    "#Show dataset loading visualization\n",
    "#from tqdm import tqdm\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "#Serializer\n",
    "def deserialize(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        obj =  yaml.load(f, Loader=yaml.FullLoader)\n",
    "        return (obj['img_file_name'], obj['data'])\n",
    "        \n",
    "#Defining dataset class\n",
    "class Faces_dataset(Dataset):\n",
    "    def __init__(self,transform=None):\n",
    "        self.data =[]#data of cv2 pics and labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img=self.data[idx][0]\n",
    "        label=self.data[idx][1]\n",
    "        if self.transform:\n",
    "            img=self.transform(img)\n",
    "        return (img, label)\n",
    "    \n",
    "    def add(self, item, label):\n",
    "        self.data.append((item,label))\n",
    "\n",
    "    #Create dataset function\n",
    "def load_data(location,classid,dataset=None):\n",
    "    if dataset is None:\n",
    "        dataset=Faces_dataset(ToTensor())\n",
    "    mainPic=None\n",
    "    roiList=[]\n",
    "    roi_size=(64,64)\n",
    "    for yml in os.listdir(location):\n",
    "        if yml.endswith(\".yaml\"):\n",
    "            fname,roiList=deserialize(os.path.join(location, yml))\n",
    "                #ROI\n",
    "            if os.path.isfile(os.path.join(location, fname)):\n",
    "                mainPic=cv2.imread(os.path.join(location, fname))\n",
    "                for p1, p2 in roiList:\n",
    "                    p1 = tuple([int(v) for v in p1])\n",
    "                    p2 = tuple([int(v) for v in p2])\n",
    "                    roi=mainPic[p1[1]:p2[1],p1[0]:p2[0]]\n",
    "                    roi=cv2.resize(roi,roi_size)\n",
    "                    dataset.add(roi,classid)\n",
    "            mainPic=None   \n",
    "    return dataset\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------    \n",
    "\n",
    "#Defining model class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 2, 4)\n",
    "        self.conv2 = nn.Conv2d(2, 4, 4)\n",
    "        self.conv3 = nn.Conv2d(4, 6, 4)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(6*4*4, 26)\n",
    "        self.fc2 = nn.Linear(26, 7)\n",
    "        self.fc3 = nn.Linear(7, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,6*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#Train function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "#Test function\n",
    "best=0\n",
    "def test(dataloader, model,loss_fn):\n",
    "    global best\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    best=100*correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "#Defining device (cpu/gpu).\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "#Helpers\n",
    "BASE_DIR=os.getcwd()\n",
    "MODEL_DIR=os.path.join(BASE_DIR,'model')\n",
    "#Model\n",
    "model = NeuralNetwork().to(device)\n",
    "USE_SAVED_MODEL=False\n",
    "LOAD_PATH=os.path.join(MODEL_DIR,\"model.pth\")\n",
    "SAVE_TRAINED_MODEL=True\n",
    "SAVE_PATH=os.path.join(MODEL_DIR,\"model.pth\")\n",
    "#Params\n",
    "LOAD_DATA_TRAIN=True\n",
    "LOCATION_DATA_TRAIN=\"data/train\"\n",
    "LOCATION_BAD_DATA_TRAIN=\"data/badtrain\"\n",
    "LOAD_DATA_TEST=True\n",
    "LOCATION_DATA_TEST=\"data/test\"\n",
    "LOCATION_BAD_DATA_TEST=\"data/badtest\"\n",
    "#Hyperparams\n",
    "BATCH_SIZE=16\n",
    "EPOCHS=500\n",
    "LEARNING_RATE=1e-2\n",
    "MOMENTUM=0.8\n",
    "#Loss and optimizer\n",
    "LOSS_FN = nn.CrossEntropyLoss() #Loss calculation function\n",
    "OPTIMIZER = torch.optim.SGD(model.parameters(), LEARNING_RATE, MOMENTUM) #Train function\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "#Load model to device and print it\n",
    "if(USE_SAVED_MODEL):\n",
    "    model.load_state_dict(torch.load(LOAD_PATH)) #load saved model\n",
    "print(model)\n",
    "\n",
    "#Training data\n",
    "if(LOAD_DATA_TRAIN):\n",
    "    training_data=load_data(LOCATION_DATA_TRAIN,1)\n",
    "    training_data=load_data(LOCATION_BAD_DATA_TRAIN,0,training_data)\n",
    "    print(\"Training data count:\",len(training_data))\n",
    "#Test data\n",
    "if(LOAD_DATA_TEST):\n",
    "    test_data=load_data(LOCATION_DATA_TEST,1)\n",
    "    test_data=load_data(LOCATION_BAD_DATA_TEST,0,test_data)\n",
    "    print(\"Test data count:\",len(test_data))\n",
    "\n",
    "\n",
    "#Data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data))\n",
    "\n",
    "\n",
    "#Data loaders info (!)\n",
    "'''\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "'''\n",
    "    \n",
    "    \n",
    "#Training\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, LOSS_FN, OPTIMIZER)\n",
    "    test(test_dataloader, model,LOSS_FN)\n",
    "print(\"Done!\")\n",
    "\n",
    "#Save\n",
    "if(SAVE_TRAINED_MODEL):\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    print(\"Saved PyTorch Model State to \\\"{0}\\\"\".format(SAVE_PATH))\n",
    "\n",
    "\n",
    "#Defined classes of outputs\n",
    "classes = [\n",
    "    \"Not face\",\n",
    "    \"Face\"\n",
    "]\n",
    "\n",
    "#Model in use (!)\n",
    "'''\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "'''\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ann] *",
   "language": "python",
   "name": "conda-env-ann-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
